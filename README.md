# Homework#1 for machine learning course

## Что лежит в репозиории:
- тетрадка ai_hw.ipynb с полным домашним заданием
- скрипт main.py с реализацией сервиса на fastapi
- папка models с моделью, one-hot энкодером и scaler'ом в формате pickle
- папка screenshots со скринами работы сервиса
- файл test_data.csv с тестовыми данными для проверки работы предсказаний на основе csv файла
- файл results.csv с результатом работы сервера на предсказание на основе csv файла

## Результаты работы:
### 1. Обработка данных
- в изначальном датасете встречались 1159 полных дубликатов, которые были удалены
- текстовые признаки были преобразованы в числовые двумя способами: если признак содержит число, то число выделялось из текста (mileage, engine, max_power, torque), иначе признаки были обработаны методом one-hot encoding (name, fuel, seller_type, transmission, owner, seats)
- пропуски были заполнены медианой (mileage, engine, max_power, torque, seats, max_torque_rpm)

### 2. Анализ данных
- есть заметная корреляция переменных torque и max_power, max_power и engine
- max_torque_rpm и max_power наименнее скоррелированы, так как модуль их коэффициента кореляции ближе всего к нулю
- графики зависимостей переменных для тестовой и обучающей выборки визуально похожи, что может указывать на то, что обучающая выборка хорошо отражает тестовые данные

### 3. Эксперименты только с числовыми характеристиками
- все эксперименты показали почти одинаковые результаты
- обучались различные варианты линейной регрессии: просто линейная регрессия, с L0 и L1 регуляризацией, ElasticNet, с L0 регуляризацией
- были проведены эксперименты с числовыми признаками до и после нормализации
- для подбора параметров использовался GridSearch
- результаты для этих экспериментов: r2 = 0.603; mse = 228e9

### 4. Эксперименты добавлением категориальных характеристик
- как уже говорилось, категориальные переменные были обработаны с помощью one-hot encoder'а
- результаты сильно выросли на модели с L2 регуляризацией: r2 = 0.79; mse = 119e9

### 5. Бизнес-метрики
- помимо ml-метрик были получены результаты по двум бизнес метрикам: доля прогнозов, отличающихся не более чем на 10%, а также такая же метрика с учетом того, что недопрогноз для модели, согласно мнению бизнеса, хуже, чем перепрогноз
- в результате последняя модель с добавлением категориальных признаков оказалась лучше

### 6. Результаты
- удалось реализовать модель для предсказания стоимости автомобиля по его основным характеристикам, были проведены эксперименты с различными моделями и методами обработки данных
- лучший результат показала Ridge регрессия после добавления обработки категориальных переменных
- наибольший буст дало добавление категориальных переменных
- не успелось добавить feature engineering'а, чтобы как-то усложнить модель и добавить нелинейности в предсказание:(
